# ðŸ’¡ RL-Inverted-Pendulum-Analysis

This project endeavors to explore the intricate domain of reinforcement learning through the investigation and implementation of diverse Deep Q-Network (DQN) and Actor-Critic architectures. Our primary objective is to harness these advanced frameworks to address the intricate dynamics of the pendulum environment, a quintessential challenge in control theory.

By conducting meticulous experimentation and in-depth analysis, our aim is to unearth valuable insights into the efficacy and performance of various reinforcement learning algorithms when confronted with complex control tasks. Furthermore, we are committed to delving into methodologies aimed at augmenting the stability and convergence of these algorithms, thereby laying the groundwork for more resilient and efficient solutions applicable in real-world scenarios.

Throughout our exploration, we have explored a multitude of reinforcement learning agents, including DQN, DDQN, and SAC, in tackling the pendulum task. Given the continuous nature of the pendulum environment, we have also delved into the discretization of action spaces, particularly relevant for DQN models primarily designed for discrete action spaces.





